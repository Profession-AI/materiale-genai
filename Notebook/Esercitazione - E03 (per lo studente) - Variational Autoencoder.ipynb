{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1hl5ngdWXMW0bjceh6q3vR3IYOVnQja5t","authorship_tag":"ABX9TyMjysb4Z5Kgq5o447oVEOrk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Esercitazione - E03 - Variational Autoencoder\n","\n","Scarica un dataset di immagini reali, costruisci il tuo variational autoencoder e allenalo per generare immagini!\n","\n","* Usa il dataset [Oxford 102 Flowers](https://pytorch.org/vision/0.16/generated/torchvision.datasets.Flowers102.html#torchvision.datasets.Flowers102).\n","\n","* Le immagini di questo dataset in genere hanno shape (3, 128, 128), ma per velocizzare il training puoi usare anche la dimensione (3, 64, 64).\n","\n","* Costruisci un variational autoencoder basato su reti convoluzionali!\n","\n","* Nei casi reali, stai attento al bilanciamento tra la loss KL e la loss di ricostruzione! spesso, conviene moltiplicare la KL per un valore piccolo (ad esempio 0.0005) perché i suoi valori sono molto più grandi.\n","\n","⚠️ Puoi utilizzare blocchi di codice che abbiamo scritto nei notebook precedenti!"],"metadata":{"id":"RxAthPlpXBkC"}},{"cell_type":"code","source":["# Colleghiamo Google Drive per salvare risultati, immagini, e checkpoints\n"],"metadata":{"id":"8TtjP2EX5YvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import"],"metadata":{"id":"DvK5TaG5gyKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Impostiamo gli hyperparametri\n"],"metadata":{"id":"PU7pHSxFg5ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Trasformazioni delle immagini\n","def to_img(x):\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 3, 64, 64)\n","    return x\n","\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((64, 64)),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"],"metadata":{"id":"Ui4dn1ryg_jW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scarichiamo e prepariamo il dataset\n"],"metadata":{"id":"MtlnMYHIhDZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('/content/drive/MyDrive/Colabs/vae_img'):\n","    os.mkdir('/content/drive/MyDrive/Colabs/vae_img')\n","\n","# Definiamo il modello"],"metadata":{"id":"wpVJ0APGjIns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definiamo un'istanza del modello, spostiamo su GPU\n","\n","# Definiamo l'ottimizzatore"],"metadata":{"id":"2pboteGUiLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhJXlenVYBfk"},"outputs":[],"source":["# Alleniamo il nostro VAE"]},{"cell_type":"code","source":["# Generiamo alcuni nuovi campioni"],"metadata":{"id":"ErzgBW22jWHz"},"execution_count":null,"outputs":[]}]}