{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMJzpfv8loouDRuxcXx6mLj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"dsfv8O28ehbf","executionInfo":{"status":"ok","timestamp":1700645202828,"user_tz":-60,"elapsed":343,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}}},"outputs":[],"source":["import os\n","import imageio\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision import datasets\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n","from torch.autograd import grad as torch_grad"]},{"cell_type":"code","source":["# Impostiamo gli hyperparametri\n","\n","# Iperparametri generali\n","batch_size = 64\n","num_epoch = 100\n","z_dimension = 100  # dimensione del vettore di rumore in input al generatore\n","# clip_value = 0.01\n","\n","# Iperparametri ottimizzatore\n","learning_rate = 1e-4\n","b1 = 0.9\n","b2 = 0.999\n","\n","# Iperparametri per la WGAN\n","n_critic = 5\n","gp_weight = 10\n","\n","# Trasformazione delle immagini\n","def to_img(x):\n","    out = 0.5 * (x + 1)\n","    out = out.clamp(0, 1)\n","    out = out.view(-1, 1, 28, 28)\n","    return out\n","\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((32, 32))\n","    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"],"metadata":{"id":"0bUsV3BC7Unl","executionInfo":{"status":"ok","timestamp":1700653853516,"user_tz":-60,"elapsed":263,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["# Solita dataset ;)\n","dataset = datasets.MNIST('./data', transform=img_transform, download=True)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"t9akRmpV7WIZ","executionInfo":{"status":"ok","timestamp":1700653854548,"user_tz":-60,"elapsed":1,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('./w_img'):\n","    os.mkdir('./w_img')\n","\n","\n","# Definiamo la classe dei modelli nella GAN:\n","# Discriminatore\n","class WDiscriminator(nn.Module):\n","    def __init__(self, img_size=32, dim=16):\n","        \"\"\"\n","        img_size : (int, int, int)\n","            Height and width must be powers of 2.  E.g. (32, 32, 1) or\n","            (64, 128, 3). Last number indicates number of channels, e.g. 1 for\n","            grayscale or 3 for RGB\n","        \"\"\"\n","        super(WDiscriminator, self).__init__()\n","\n","        self.img_size = img_size\n","\n","        self.image_to_features = nn.Sequential(\n","            nn.Conv2d(1, dim, 4, 2, 1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        # 4 convolutions of stride 2, i.e. halving of size everytime\n","        # So output size will be 8 * (img_size / 2 ^ 4) * (img_size / 2 ^ 4)\n","        output_size = int(8 * dim * (img_size / 16) * (img_size / 16))\n","        # output_size = 128\n","        self.features_to_prob = nn.Sequential(\n","            nn.Linear(output_size, 1),\n","            # nn.Sigmoid()\n","        )\n","        print(\"output_size\", output_size)\n","\n","    def forward(self, input_data):\n","        batch_size = input_data.size()[0]\n","        x = self.image_to_features(input_data)\n","        print(\"x.shape\", x.shape)\n","        x = x.view(batch_size, -1)\n","        print(\"x_view.shape\", x.shape)\n","        return self.features_to_prob(x)\n","\n","# Generatore\n","class Generator(nn.Module):\n","    def __init__(self, img_size=32, latent_dim=z_dimension, dim=16):\n","        super(Generator, self).__init__()\n","\n","        self.dim = dim\n","        self.latent_dim = latent_dim\n","        # self.img_size = (img_size, img_size, 1)\n","        # self.feature_sizes = (self.img_size[0] / 16, self.img_size[1] / 16)\n","\n","        self.img_size = img_size\n","        self.feature_sizes = int(img_size / 16)\n","        # self.feature_sizes = int(img_size / 14)\n","\n","        # print(self.feature_sizes)\n","\n","        self.latent_to_features = nn.Sequential(\n","            # nn.Linear(latent_dim, 8 * dim * self.feature_sizes[0] * self.feature_sizes[1]),\n","            nn.Linear(latent_dim, 8 * dim * self.feature_sizes * self.feature_sizes),\n","            nn.ReLU()\n","        )\n","\n","        self.features_to_image = nn.Sequential(\n","            nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(4 * dim),\n","            nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(2 * dim),\n","            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(dim),\n","            nn.ConvTranspose2d(dim, 1, 4, 2, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input_data):\n","        # Map latent into appropriate size for transposed convolutions\n","        x = self.latent_to_features(input_data)\n","        # Reshape\n","        # x = x.view(-1, 8 * self.dim, self.feature_sizes[0], self.feature_sizes[1])\n","        x = x.view(-1, 8 * self.dim, self.feature_sizes, self.feature_sizes)\n","        # Return generated image\n","        return self.features_to_image(x)\n","\n","    def sample_latent(self, num_samples):\n","        return torch.randn((num_samples, self.latent_dim))"],"metadata":{"id":"yVYmGP_d7X3v","executionInfo":{"status":"ok","timestamp":1700653879972,"user_tz":-60,"elapsed":275,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["class Trainer():\n","    def __init__(self, G, D, g_optimizer, d_optimizer,\n","                 gp_weight=gp_weight, critic_iterations=n_critic, print_every=50,\n","                 use_cuda=True):\n","        self.G = G\n","        self.G_opt = g_optimizer\n","        self.D = D\n","        self.D_opt = d_optimizer\n","        self.losses = {'G': [], 'D': [], 'GP': [], 'gradient_norm': []}\n","        self.num_steps = 0\n","        self.use_cuda = use_cuda\n","        self.gp_weight = gp_weight\n","        self.critic_iterations = critic_iterations\n","        self.print_every = print_every\n","\n","        if self.use_cuda:\n","            self.G.cuda()\n","            self.D.cuda()\n","\n","    def _critic_train_iteration(self, data):\n","        \"\"\" \"\"\"\n","        # Get generated data\n","        batch_size = data.size()[0]\n","        generated_data = self.sample_generator(batch_size)\n","\n","        # Calcoliamo il valore del discriminatore su immagini reali e generate\n","        if self.use_cuda:\n","            data = data.cuda()\n","\n","        print(\"data.shape\", data.shape)\n","        print(\"generated_data.shape\", generated_data.shape)\n","\n","\n","        d_real = self.D(data)\n","        d_generated = self.D(generated_data)\n","\n","\n","        # Get gradient penalty\n","        gradient_penalty = self._gradient_penalty(data, generated_data)\n","        self.losses['GP'].append(gradient_penalty.item())\n","\n","        # Create total loss and optimize\n","        self.D_opt.zero_grad()\n","        d_loss = d_generated.mean() - d_real.mean() + gradient_penalty\n","        d_loss.backward()\n","\n","        self.D_opt.step()\n","\n","        # Record loss\n","        self.losses['D'].append(d_loss.item())\n","\n","    def _generator_train_iteration(self, data):\n","        \"\"\" \"\"\"\n","        self.G_opt.zero_grad()\n","\n","        # Get generated data\n","        batch_size = data.size()[0]\n","        generated_data = self.sample_generator(batch_size)\n","\n","        # Calculate loss and optimize\n","        d_generated = self.D(generated_data)\n","        g_loss = - d_generated.mean()\n","        g_loss.backward()\n","        self.G_opt.step()\n","\n","        # Record loss\n","        self.losses['G'].append(g_loss.item())\n","\n","    def _gradient_penalty(self, real_data, generated_data):\n","        batch_size = real_data.size()[0]\n","\n","        # Calculate interpolation\n","        alpha = torch.rand(batch_size, 1, 1, 1)\n","        alpha = alpha.expand_as(real_data)\n","        if self.use_cuda:\n","            alpha = alpha.cuda()\n","        interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n","        if self.use_cuda:\n","            interpolated = interpolated.cuda()\n","\n","        # Calculate probability of interpolated examples\n","        prob_interpolated = self.D(interpolated)\n","\n","        # Calculate gradients of probabilities with respect to examples\n","        gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n","                               grad_outputs=torch.ones(prob_interpolated.size(), requires_grad=True).cuda() if self.use_cuda else torch.ones(\n","                               prob_interpolated.size(), requires_grad=True),\n","                               create_graph=True, retain_graph=True, only_inputs=True)[0]\n","\n","        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n","        # so flatten to easily take norm per example in batch\n","        gradients = gradients.view(batch_size, -1)\n","        self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean().item())\n","\n","        # Derivatives of the gradient close to 0 can cause problems because of\n","        # the square root, so manually calculate norm and add epsilon\n","        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n","\n","        # Return gradient penalty\n","        return self.gp_weight * ((gradients_norm - 1) ** 2).mean()\n","\n","    def _train_epoch(self, data_loader):\n","        for i, data in enumerate(data_loader):\n","            self.num_steps += 1\n","            self._critic_train_iteration(data[0])\n","            # Only update generator every |critic_iterations| iterations\n","            if self.num_steps % self.critic_iterations == 0:\n","                self._generator_train_iteration(data[0])\n","\n","            if i % self.print_every == 0:\n","                print(\"Iteration {}\".format(i + 1))\n","                print(\"D: {}\".format(self.losses['D'][-1]))\n","                print(\"GP: {}\".format(self.losses['GP'][-1]))\n","                print(\"Gradient norm: {}\".format(self.losses['gradient_norm'][-1]))\n","                if self.num_steps > self.critic_iterations:\n","                    print(\"G: {}\".format(self.losses['G'][-1]))\n","\n","    def train(self, data_loader, epochs, save_training_gif=True):\n","        if save_training_gif:\n","            # Fix latents to see how image generation improves during training\n","            fixed_latents = self.G.sample_latent(64)\n","            if self.use_cuda:\n","                fixed_latents = fixed_latents.cuda()\n","            training_progress_images = []\n","\n","        for epoch in range(epochs):\n","            print(\"\\nEpoch {}\".format(epoch + 1))\n","            self._train_epoch(data_loader)\n","\n","            if save_training_gif:\n","                # Generate batch of images and convert to grid\n","                img_grid = make_grid(self.G(fixed_latents).cpu().data)\n","                # Convert to numpy and transpose axes to fit imageio convention\n","                # i.e. (width, height, channels)\n","                img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n","                # Add image grid to training progress\n","                training_progress_images.append(img_grid)\n","\n","        if save_training_gif:\n","            imageio.mimsave('./training_{}_epochs.gif'.format(epochs),\n","                            training_progress_images)\n","\n","    def sample_generator(self, num_samples):\n","        latent_samples = self.G.sample_latent(num_samples)\n","        if self.use_cuda:\n","            latent_samples = latent_samples.cuda()\n","        generated_data = self.G(latent_samples)\n","        return generated_data\n","\n","    def sample(self, num_samples):\n","        generated_data = self.sample_generator(num_samples)\n","        # Remove color channel\n","        return generated_data.data.cpu().numpy()[:, 0, :, :]"],"metadata":{"id":"od2BxXI1Weby","executionInfo":{"status":"ok","timestamp":1700654705474,"user_tz":-60,"elapsed":2,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["# Creiamo un'istanza del Discriminatore\n","D = WDiscriminator().cuda()\n","# Creiamo un'istanza del Generatore\n","# G = Generator(img_size=(32, 32, 1), latent_dim=z_dimension, dim=16).cuda()\n","G = Generator().cuda()\n","\n","# Definiamo gli ottimizzatori per il discriminatore e il generatore\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas=(b1, b2))\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=(b1, b2))"],"metadata":{"id":"sdwP1iS17ZP-","executionInfo":{"status":"ok","timestamp":1700654705844,"user_tz":-60,"elapsed":2,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"96e0dc69-ce42-4598-c7bb-795053986d14"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["output_size 512\n"]}]},{"cell_type":"code","source":["# data_loader, _ = get_mnist_dataloaders(batch_size=64)\n","# img_size = (32, 32, 1)\n","\n","# generator = Generator(img_size=img_size, latent_dim=100, dim=16)\n","# discriminator = Discriminator(img_size=img_size, dim=16)\n","\n","# print(G)\n","# print(D)\n","\n","# Initialize optimizers\n","# lr = 1e-4\n","# betas = (.9, .99)\n","# G_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=betas)\n","# D_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n","\n","# Train model\n","# epochs = 200\n","trainer = Trainer(G, D, g_optimizer, d_optimizer,\n","                  use_cuda=torch.cuda.is_available())\n","trainer.train(dataloader, num_epoch, save_training_gif=True)\n","\n","# Save models\n","name = 'mnist_model'\n","torch.save(trainer.G.state_dict(), './gen_' + name + '.pt')\n","torch.save(trainer.D.state_dict(), './dis_' + name + '.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":636},"id":"Ar0Iwcw6YX00","executionInfo":{"status":"error","timestamp":1700654706150,"user_tz":-60,"elapsed":4,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}},"outputId":"1a7558b3-3ab4-4193-db4a-62b663acb32b"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","data.shape torch.Size([64, 1, 32, 32])\n","generated_data.shape torch.Size([64, 1, 32, 32])\n","x.shape torch.Size([64, 128, 2, 2])\n","x_view.shape torch.Size([64, 512])\n","x.shape torch.Size([64, 128, 2, 2])\n","x_view.shape torch.Size([64, 512])\n","x.shape torch.Size([64, 128, 2, 2])\n","x_view.shape torch.Size([64, 512])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-104-4fc350f1cb08>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m trainer = Trainer(G, D, g_optimizer, d_optimizer,\n\u001b[1;32m     19\u001b[0m                   use_cuda=torch.cuda.is_available())\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_training_gif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Save models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-102-f0ea97853681>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, epochs, save_training_gif)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_training_gif\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-102-f0ea97853681>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_critic_train_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m# Only update generator every |critic_iterations| iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_iterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-102-f0ea97853681>\u001b[0m in \u001b[0;36m_critic_train_iteration\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Get gradient penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgradient_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_penalty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-102-f0ea97853681>\u001b[0m in \u001b[0;36m_gradient_penalty\u001b[0;34m(self, real_data, generated_data)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Calculate gradients of probabilities with respect to examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n\u001b[0m\u001b[1;32m     86\u001b[0m                                grad_outputs=torch.ones(prob_interpolated.size(), requires_grad=True).cuda() if self.use_cuda else torch.ones(\n\u001b[1;32m     87\u001b[0m                                prob_interpolated.size(), requires_grad=True),\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    392\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"]}]},{"cell_type":"code","source":["# Alleniamo le nostre reti\n","for epoch in range(num_epoch):\n","    for i, (img, _) in enumerate(dataloader):\n","        num_img = img.size(0)\n","        d_optimizer.zero_grad()\n","\n","        real_img = img.cuda()\n","        # real_label = torch.ones(num_img).cuda()\n","        # fake_label = torch.zeros(num_img).cuda()\n","\n","        # Calcoliamo la loss del Discriminatore sulle immagini reali\n","        real_out = D(real_img).squeeze(1)\n","        # d_loss_real = criterion(real_out, real_label)\n","        # real_scores = real_out  # Più è vicino a 1, meglio è\n","\n","\n","        z = torch.randn(num_img, z_dimension).cuda() # Noise di input\n","        fake_img = G(z)\n","        fake_out = D(fake_img).squeeze(1)\n","\n","        # Calcoliamo la distanza di Wasserstein\n","        d_loss = torch.mean(fake_out) - torch.mean(real_out)\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        # Clip dei pesi del discriminatore per mantenere la condizione di\n","        # 1-Lipschitz (in alternativa si può inserire la gradient penalty)\n","        for p in D.parameters():\n","            p.data.clamp_(-clip_value, clip_value)\n","\n","\n","        if i % n_critic == 0:\n","            # train Generator\n","            g_optimizer.zero_grad()\n","\n","            # Calcoliamo la loss del Generatore sulle immagini generate\n","            z = torch.randn(num_img, z_dimension).cuda() # Noise di input\n","            fake_img = G(z)\n","            # Adversarial loss\n","            g_loss = -torch.mean(D(fake_img))\n","            g_loss.backward()\n","            g_optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print('Epoch [{}/{}], d_loss: {:.6f}, g_loss: {:.6f}'\n","                    .format(epoch, num_epoch, d_loss.item(), g_loss.item()))\n","    if epoch == 0:\n","        real_images = to_img(real_img.cpu().data)\n","        save_image(real_images, './w_img/real_images.png')\n","\n","    fake_images = to_img(fake_img.cpu().data)\n","    save_image(fake_images, './w_img/fake_images-{}.png'.format(epoch+1))\n","\n","torch.save(G.state_dict(), './generator.pth')\n","torch.save(D.state_dict(), './discriminator.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2bnuk0HJ7mEo","executionInfo":{"status":"error","timestamp":1700411487733,"user_tz":-60,"elapsed":1654548,"user":{"displayName":"Eleonora Grassucci","userId":"15233023825143080101"}},"outputId":"57c53be9-2e7c-47ed-e3d8-395f2200a494"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [0/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [0/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [0/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [0/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [1/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [1/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [1/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [1/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [2/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [2/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [2/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [2/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [3/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [3/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [3/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [3/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [4/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [4/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [4/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [4/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [5/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [5/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [5/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [5/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [6/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [6/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [6/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [6/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [7/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [7/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [7/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [7/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [8/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [8/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [8/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [8/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [9/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [9/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [9/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [9/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [10/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [10/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [10/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [10/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [11/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [11/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [11/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [11/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [12/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [12/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [12/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [12/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [13/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [13/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [13/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [13/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [14/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [14/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [14/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [14/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [15/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [15/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [15/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [15/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [16/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [16/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [16/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [16/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [17/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [17/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [17/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [17/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [18/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [18/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [18/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [18/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [19/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [19/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [19/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [19/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [20/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [20/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [20/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [20/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [21/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [21/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [21/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [21/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [22/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [22/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [22/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [22/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [23/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [23/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [23/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [23/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [24/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [24/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [24/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [24/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [25/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [25/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [25/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [25/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [26/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [26/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [26/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [26/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [27/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [27/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [27/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [27/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [28/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [28/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [28/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [28/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [29/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [29/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [29/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [29/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [30/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [30/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [30/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [30/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [31/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [31/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [31/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [31/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [32/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [32/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [32/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [32/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [33/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [33/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [33/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [33/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [34/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [34/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [34/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [34/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [35/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [35/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [35/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [35/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [36/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [36/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [36/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [36/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [37/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [37/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [37/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [37/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [38/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [38/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [38/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [38/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [39/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [39/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [39/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [39/100], d_loss: -0.000000, g_loss: -0.000100\n","Epoch [40/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [40/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [40/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [40/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [41/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [41/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [41/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [41/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [42/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [42/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [42/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [42/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [43/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [43/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [43/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [43/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [44/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [44/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [44/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [44/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [45/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [45/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [45/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [45/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [46/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [46/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [46/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [46/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [47/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [47/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [47/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [47/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [48/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [48/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [48/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [48/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [49/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [49/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [49/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [49/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [50/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [50/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [50/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [50/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [51/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [51/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [51/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [51/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [52/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [52/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [52/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [52/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [53/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [53/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [53/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [53/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [54/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [54/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [54/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [54/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [55/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [55/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [55/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [55/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [56/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [56/100], d_loss: 0.000000, g_loss: -0.000102\n","Epoch [56/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [56/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [57/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [57/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [57/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [57/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [58/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [58/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [58/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [58/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [59/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [59/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [59/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [59/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [60/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [60/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [60/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [60/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [61/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [61/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [61/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [61/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [62/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [62/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [62/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [62/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [63/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [63/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [63/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [63/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [64/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [64/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [64/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [64/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [65/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [65/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [65/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [65/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [66/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [66/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [66/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [66/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [67/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [67/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [67/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [67/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [68/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [68/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [68/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [68/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [69/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [69/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [69/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [69/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [70/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [70/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [70/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [70/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [71/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [71/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [71/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [71/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [72/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [72/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [72/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [72/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [73/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [73/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [73/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [73/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [74/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [74/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [74/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [74/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [75/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [75/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [75/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [75/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [76/100], d_loss: -0.000000, g_loss: -0.000101\n","Epoch [76/100], d_loss: -0.000000, g_loss: -0.000102\n","Epoch [76/100], d_loss: -0.000000, g_loss: -0.000102\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-a2c6d4c4f44e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mreal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# real_label = torch.ones(num_img).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# fake_label = torch.zeros(num_img).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Generiamo nuovi campioni\n","z = torch.randn(4, z_dimension).cuda()\n","fake_img = G(z)\n","\n","# Guardiamo i campioni generati\n","plt.subplot(2,2,1)\n","plt.imshow(fake_img.detach().cpu()[0][0], cmap=\"gray\")\n","plt.subplot(2,2,2)\n","plt.imshow(fake_img.detach().cpu()[1][0], cmap=\"gray\")\n","plt.subplot(2,2,3)\n","plt.imshow(fake_img.detach().cpu()[2][0], cmap=\"gray\")\n","plt.subplot(2,2,4)\n","plt.imshow(fake_img.detach().cpu()[3][0], cmap=\"gray\")"],"metadata":{"id":"6T42zhX292wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KKHPLfbNMRi4"},"execution_count":null,"outputs":[]}]}