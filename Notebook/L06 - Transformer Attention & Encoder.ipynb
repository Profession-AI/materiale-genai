{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2geeBbSLvnOvaIZrwwA/v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8PJ50OPBlt5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666104747,"user_tz":-60,"elapsed":28279,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"8156b9ed-e8d6-4781-9946-240c9c517dc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.16.0\n","  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bertviz==1.2.0\n","  Downloading bertviz-1.2.0-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.2/156.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2.31.0)\n","Collecting sacremoses (from transformers==4.16.0)\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.15.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (4.66.1)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz==1.2.0) (2.1.0+cu118)\n","Collecting boto3 (from bertviz==1.2.0)\n","  Downloading boto3-1.29.5-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece (from bertviz==1.2.0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz==1.2.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz==1.2.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz==1.2.0) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz==1.2.0) (2.1.0)\n","Collecting botocore<1.33.0,>=1.32.5 (from boto3->bertviz==1.2.0)\n","  Downloading botocore-1.32.5-py3-none-any.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz==1.2.0)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->bertviz==1.2.0)\n","  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2023.7.22)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (1.3.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.5->boto3->bertviz==1.2.0) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz==1.2.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz==1.2.0) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.5->boto3->bertviz==1.2.0) (1.16.0)\n","Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, transformers, boto3, bertviz\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed bertviz-1.2.0 boto3-1.29.5 botocore-1.32.5 jmespath-1.0.1 s3transfer-0.7.0 sacremoses-0.1.1 sentencepiece-0.1.99 transformers-4.16.0\n"]}],"source":["!pip install transformers==4.16.0 bertviz==1.2.0"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lJVe1J8elt5v","executionInfo":{"status":"ok","timestamp":1700666307662,"user_tz":-60,"elapsed":7341,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["from transformers import AutoTokenizer, AutoConfig\n","from bertviz.transformers_neuron_view import BertModel\n","from bertviz.neuron_view import show\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from math import sqrt\n","\n"]},{"cell_type":"markdown","source":["# Transformer Attention & Transformer Encoder"],"metadata":{"id":"BsuraUnhl_Fu"}},{"cell_type":"markdown","metadata":{"id":"9GX57x_ilt5p"},"source":["## Architettura Transformer"]},{"cell_type":"markdown","source":["Carichiamo in memoria un modello Transformer (nel nostro caso bert-base-uncased) e andiamo a vedere come funziona nel dettaglio questo tipo di architettura.\n","BERT è un modello Transformer solo Encoder"],"metadata":{"id":"rUwttNlxmrM8"}},{"cell_type":"code","source":["# Carichiamo in memoria il modello\n","model_ckpt = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","model = BertModel.from_pretrained(model_ckpt)"],"metadata":{"id":"RP44ynTVuAF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vediamo ora l'architettura di BERT: è un modello composto da un primo layer di embeddings a cui seguono 12 layer Transfomers Encoder. Ciascun Layer di tipo BertEncoder è costituito da una prima parte di SelfAttention seguito poi da una parte di Rete Neurale FeedForward."],"metadata":{"id":"W4Ulq8LdnIf0"}},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4T5MdaNem3pV","executionInfo":{"status":"ok","timestamp":1700666567099,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"dee59727-062c-4f33-8fd3-ca5261112139"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Visualizziamo ora le connessioni tra input e output, con la possibilità di scegliere i layer e la \"head\" per ciascun layer"],"metadata":{"id":"xwKV7IhCoHWk"}},{"cell_type":"code","source":["text = \"time flies like an arrow\"\n","show(model, \"bert\", tokenizer, text, display_mode=\"light\", layer=0, head=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338,"output_embedded_package_id":"1PgQ_RmR1LpibW2puEo2Xn1ENkH3S-xmW"},"id":"5DuXr44cm8gd","executionInfo":{"status":"ok","timestamp":1700666401473,"user_tz":-60,"elapsed":3750,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"ebb94255-950f-45ae-9bcd-86bb40a73c74"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Andiamo nei dettagli e implementiamo pezzo dopo pezzo i building block necessari per costruire un modello Transformers\n"],"metadata":{"id":"wTlhINdOqw4z"}},{"cell_type":"markdown","metadata":{"id":"gtuUZ2Xylt5w"},"source":["### Vediamo che cosa sono le Queries, Keys, and Values e come si usano per calcolare l'Attention"]},{"cell_type":"markdown","source":["Carichiamo anche il tokenizer e creiamo il nostro vettore di embeddings, dopo aver convertito l'input testuale in un vettore."],"metadata":{"id":"oWEsM-nqo2GQ"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZsxomHtJlt5w","executionInfo":{"status":"ok","timestamp":1700666709789,"user_tz":-60,"elapsed":2149,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["model_ckpt = \"bert-base-uncased\"\n","text = \"time flies like an arrow\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7pv1PdF3lt5w","outputId":"a8d2a20b-8dc3-428d-cc03-42ca8a4a7e11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666709790,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2051, 10029,  2066,  2019,  8612]])"]},"metadata":{},"execution_count":9}],"source":["inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","inputs.input_ids"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"zXpGzGrIlt5x","outputId":"97d8fceb-0061-46d6-cef2-008a262a3827","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666719249,"user_tz":-60,"elapsed":1341,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768)"]},"metadata":{},"execution_count":10}],"source":["config = AutoConfig.from_pretrained(model_ckpt)\n","token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n","token_emb"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sLUYWVlUlt5x","outputId":"635c8224-6670-4c46-9224-efb776248c7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666724646,"user_tz":-60,"elapsed":250,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":11}],"source":["inputs_embeds = token_emb(inputs.input_ids)\n","inputs_embeds.size()"]},{"cell_type":"markdown","source":["A questo punto, definiamo queries, keys e values come la nostra matrice che mappa gli input negli embeddings.\n","Per calcolare gli scores, effettuiamo una moltiplicazione tra matrici tra le query e le keys"],"metadata":{"id":"6z5_IIw-pC7b"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"jJuxbgpKlt5y","outputId":"7f207ced-eba7-401c-cb15-557e7d0812ec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666903069,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 5])"]},"metadata":{},"execution_count":12}],"source":["query = key = value = inputs_embeds\n","dim_k = key.size(-1)\n","scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n","scores.size()"]},{"cell_type":"markdown","source":["Passiamo i nostri scores attraverso una funzione di softmax"],"metadata":{"id":"anunxm9fpjdl"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"oKyXYVAllt5z","outputId":"06f7f3b7-a9c6-4e36-81f0-171bb20d8b4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666963116,"user_tz":-60,"elapsed":320,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"]},"metadata":{},"execution_count":13}],"source":["weights = F.softmax(scores, dim=-1)\n","weights.sum(dim=-1)"]},{"cell_type":"markdown","source":["E infine, calcoliamo il valore dell'attention moltiplicando questo vettore con i values"],"metadata":{"id":"WjrSAd_UpnrF"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"-s9IOfozlt5z","outputId":"285a622f-91b5-48e2-a253-a91446ddde62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700666980279,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":14}],"source":["attn_outputs = torch.bmm(weights, value)\n","attn_outputs.shape"]},{"cell_type":"markdown","source":["Riepilogando, creiamo una funzione che calcola i valori di Attention partendo dalle 3 matrici di query, key e value:"],"metadata":{"id":"hL3wNhWtpwGz"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"tgKpewUclt5z","executionInfo":{"status":"ok","timestamp":1700667036000,"user_tz":-60,"elapsed":2,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["def scaled_dot_product_attention(query, key, value):\n","    dim_k = query.size(-1)\n","    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","    weights = F.softmax(scores, dim=-1)\n","    return torch.bmm(weights, value)"]},{"cell_type":"markdown","metadata":{"id":"gRp1YOGLlt5z"},"source":["#### Multi-headed attention"]},{"cell_type":"markdown","source":["Definiamo quindi una classe AttentionHead che rappresenta un modulo"],"metadata":{"id":"rxFQmqwVqAWW"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"QJWjSFCtlt50","executionInfo":{"status":"ok","timestamp":1700667168979,"user_tz":-60,"elapsed":351,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class AttentionHead(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super().__init__()\n","        self.q = nn.Linear(embed_dim, head_dim)\n","        self.k = nn.Linear(embed_dim, head_dim)\n","        self.v = nn.Linear(embed_dim, head_dim)\n","\n","    def forward(self, hidden_state):\n","        attn_outputs = scaled_dot_product_attention(\n","            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n","        return attn_outputs"]},{"cell_type":"markdown","source":["Combiniamo insieme le nostre attention head per creare un modulo di MultiHead!"],"metadata":{"id":"Xc4qxs-eqNME"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"e0zZzzLflt50","executionInfo":{"status":"ok","timestamp":1700667169323,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        embed_dim = config.hidden_size\n","        num_heads = config.num_attention_heads\n","        head_dim = embed_dim // num_heads\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n","        )\n","        self.output_linear = nn.Linear(embed_dim, embed_dim)\n","\n","    def forward(self, hidden_state):\n","        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n","        x = self.output_linear(x)\n","        return x"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"CWBtF6GClt50","outputId":"af73eb6b-d567-4833-c460-bea25164b32f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700667169877,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":20}],"source":["multihead_attn = MultiHeadAttention(config)\n","attn_output = multihead_attn(inputs_embeds)\n","attn_output.size()"]},{"cell_type":"markdown","metadata":{"id":"REB-rP95lt51"},"source":["### Implementiamo ora il layer della Rete Neurale Feed Forward"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"J5p2UC3Glt51","executionInfo":{"status":"ok","timestamp":1700667366681,"user_tz":-60,"elapsed":286,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.gelu(x)\n","        x = self.linear_2(x)\n","        x = self.dropout(x)\n","        return x"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"NO_U-547lt52","outputId":"b9ae2a5c-9cfd-438f-e14a-8e07443ab480","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700667392247,"user_tz":-60,"elapsed":288,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":24}],"source":["feed_forward = FeedForward(config)\n","ff_outputs = feed_forward(attn_outputs)\n","ff_outputs.size()"]},{"cell_type":"markdown","metadata":{"id":"P2_BJvySlt52"},"source":["### Creiamo quindi un modulo che rappresenta un layer di un modello Transformer Encoder (aggiungendo anche la Layer Normalization)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"koFQ0DQalt52","executionInfo":{"status":"ok","timestamp":1700667500847,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n","        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n","        self.attention = MultiHeadAttention(config)\n","        self.feed_forward = FeedForward(config)\n","\n","    def forward(self, x):\n","        # Apply layer normalization and then copy input into query, key, value\n","        hidden_state = self.layer_norm_1(x)\n","        # Apply attention with a skip connection\n","        x = x + self.attention(hidden_state)\n","        # Apply feed-forward layer with a skip connection\n","        x = x + self.feed_forward(self.layer_norm_2(x))\n","        return x"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"v39i_Watlt53","outputId":"dc0a6d1f-21c9-40ff-c5e1-8c65ec2d41de","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700667501272,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 5, 768]), torch.Size([1, 5, 768]))"]},"metadata":{},"execution_count":28}],"source":["encoder_layer = TransformerEncoderLayer(config)\n","inputs_embeds.shape, encoder_layer(inputs_embeds).size()"]},{"cell_type":"markdown","metadata":{"id":"xVH8r19Hlt53"},"source":["### Aggiungiamo anche una classe che rappresenta gli embeddings (combinati con i Positional Embeddings - che danno informazioni in base alla posizione in cui sono gli input)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"FRzkSzrGlt53","executionInfo":{"status":"ok","timestamp":1700667588395,"user_tz":-60,"elapsed":382,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class Embeddings(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.token_embeddings = nn.Embedding(config.vocab_size,\n","                                             config.hidden_size)\n","        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n","                                                config.hidden_size)\n","        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n","        self.dropout = nn.Dropout()\n","\n","    def forward(self, input_ids):\n","        # Create position IDs for input sequence\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n","        # Create token and position embeddings\n","        token_embeddings = self.token_embeddings(input_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","        # Combine token and position embeddings\n","        embeddings = token_embeddings + position_embeddings\n","        embeddings = self.layer_norm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"uRipr7VIlt53","outputId":"bfc35b3b-ff43-4a16-a80f-fc2199603bb4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700667588688,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":30}],"source":["embedding_layer = Embeddings(config)\n","embedding_layer(inputs.input_ids).size()"]},{"cell_type":"markdown","source":["Siamo quindi pronti per definire il nostro modello Transformers Encoder, combinando il layer di Embeddings con una serie di layer di tipo TransformerEncoderLayer definiti in precedenza"],"metadata":{"id":"TgpSwZhtsC4u"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"MbVL68gnlt59","executionInfo":{"status":"ok","timestamp":1700667933349,"user_tz":-60,"elapsed":261,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embeddings = Embeddings(config)\n","        self.layers = nn.ModuleList([TransformerEncoderLayer(config)\n","                                     for _ in range(config.num_hidden_layers)])\n","\n","    def forward(self, x):\n","        x = self.embeddings(x)\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"N2h_Ylhdlt59","outputId":"597e3b73-d74f-48d4-d388-a89dfbdcc1ef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700667936124,"user_tz":-60,"elapsed":2440,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":34}],"source":["encoder = TransformerEncoder(config)\n","encoder(inputs.input_ids).size()"]},{"cell_type":"code","source":["encoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OT8X3xu7tUEX","executionInfo":{"status":"ok","timestamp":1700667939081,"user_tz":-60,"elapsed":317,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"fc801d54-a748-4728-cceb-efecf3697853"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerEncoder(\n","  (embeddings): Embeddings(\n","    (token_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (layers): ModuleList(\n","    (0-11): 12 x TransformerEncoderLayer(\n","      (layer_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-11): 12 x AttentionHead(\n","            (q): Linear(in_features=768, out_features=64, bias=True)\n","            (k): Linear(in_features=768, out_features=64, bias=True)\n","            (v): Linear(in_features=768, out_features=64, bias=True)\n","          )\n","        )\n","        (output_linear): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (feed_forward): FeedForward(\n","        (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n","        (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n","        (gelu): GELU(approximate='none')\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":[],"metadata":{"id":"s63a_EIBtVS5"},"execution_count":null,"outputs":[]}]}