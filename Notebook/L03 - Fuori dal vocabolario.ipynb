{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699465387683,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"},"user_tz":-60},"id":"fGHwwchkIdcA","outputId":"a07c0062-f4c9-471c-fa74-17d933fac7ce"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":40}],"source":["from sklearn.datasets import fetch_20newsgroups         # Dataset che contiene testo di articoli di giornale appartenenti a 20 categorie differenti\n","import nltk                                             # NLP toolkit\n","import re                                               # Libreria per operazioni con le espressioni regolari\n","from collections import defaultdict, Counter\n","import numpy as np\n","import pandas as pd\n","import itertools\n","import random\n","\n","nltk.download('punkt')                                  # Con questo comando si scarica il tokenizzatore 'Punkt'"]},{"cell_type":"markdown","metadata":{"id":"-pPB2noLN26s"},"source":["## Scarichiamo il nostro dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kx_TWkYlL1WA"},"outputs":[],"source":["train_news_texts, category = fetch_20newsgroups(subset=\"train\", categories=[\"sci.space\"], return_X_y=True, remove=['headers', 'footers', 'quotes'])"]},{"cell_type":"markdown","source":["## Definiamo la funzione creata in precedenza per processare il dataset e creare gli N-Grammi"],"metadata":{"id":"sUOUZdibZZJx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWAMly0ZUFAQ"},"outputs":[],"source":["def preprocessing(text, n):\n","    \"\"\"\n","    Funzione che preprocessa il testo per creare una frase tokenizzata.\n","\n","    Args:\n","        text: stringa contenente il testo da preprocessare e tokenizzare\n","\n","    Returns:\n","        testo preprocessato e tokenizzato\n","    \"\"\"\n","    text = text.lower()\n","    text = text.replace('\\n', ' ')\n","    text = re.sub(r'[^a-zA-Z0-9.?! ]+', '', text)\n","    text = re.sub(' +', ' ', text)\n","    text = text.strip()\n","    text_tokenized = nltk.word_tokenize(text)\n","    text_tokenized = ['<s>'] * (n - 1) + text_tokenized + ['</s>']\n","    return text_tokenized\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s608UvXxRCOz"},"outputs":[],"source":["def sentence_to_ngram(tokenized_sentence, n=3):\n","    \"\"\"\n","    Funzione che restituisce tutti i n-grammi contenuti all'interno della frase tokenizzata.\n","\n","    Args:\n","        tokenized_sentence: lista di parole/tokens che compongono la frase\n","        n: n-grammi da considerare\n","\n","    Returns:\n","        lista di tutti i n-grammi presenti all'interno della frase tokenizzata\n","    \"\"\"\n","\n","    ngram_list = []\n","    for i in range(len(tokenized_sentence) - n + 1):\n","        # the sliding window starts at position i and contains 3 words\n","        ngram = tokenized_sentence[i : i + n]\n","        ngram_list.append(ngram)\n","    return ngram_list\n","\n"]},{"cell_type":"markdown","source":["# Prendiamo due frasi come esempio"],"metadata":{"id":"rlievngTM3bf"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699467592907,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"},"user_tz":-60},"id":"vZonBlLDT274","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f0007ab-6a12-4e72-a300-df57af0f925f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Any lunar satellite needs fuel to do regular orbit corrections, and when\n","its fuel runs out it will crash within months.\n","--------------------------------------------------------------------------------\n","The orbits of the Apollo\n","motherships changed noticeably during lunar missions lasting only a few\n","days.\n","--------------------------------------------------------------------------------\n","Any lunar satellite needs fuel to do regular orbit corrections, and when\n","its fuel runs out it will crash within months.\n","--------------------------------------------------------------------------------\n"]}],"source":["n = 3\n","train_news_texts_sample = [nltk.sent_tokenize(train_news_texts[0].strip())[0], nltk.sent_tokenize(train_news_texts[0].strip())[1],  nltk.sent_tokenize(train_news_texts[0].strip())[0]]\n","for text in train_news_texts_sample:\n","  print(text)\n","  print(\"-\"*80)\n"]},{"cell_type":"markdown","source":["# Creiamo il corpus e definiamo il vocabolario con le 10 parole più comuni\n"],"metadata":{"id":"9zBjjfycNB8n"}},{"cell_type":"code","source":["train_news_texts_sample_processed = [preprocessing(text, n) for text in train_news_texts_sample]\n","corpus = [x for y in train_news_texts_sample_processed for x in y]\n","corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5t23PTvbiy4","executionInfo":{"status":"ok","timestamp":1699467649497,"user_tz":-60,"elapsed":476,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"5da5f3e7-7977-4c55-f263-f2736158c99a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s>',\n"," '<s>',\n"," 'any',\n"," 'lunar',\n"," 'satellite',\n"," 'needs',\n"," 'fuel',\n"," 'to',\n"," 'do',\n"," 'regular',\n"," 'orbit',\n"," 'corrections',\n"," 'and',\n"," 'when',\n"," 'its',\n"," 'fuel',\n"," 'runs',\n"," 'out',\n"," 'it',\n"," 'will',\n"," 'crash',\n"," 'within',\n"," 'months',\n"," '.',\n"," '</s>',\n"," '<s>',\n"," '<s>',\n"," 'the',\n"," 'orbits',\n"," 'of',\n"," 'the',\n"," 'apollo',\n"," 'motherships',\n"," 'changed',\n"," 'noticeably',\n"," 'during',\n"," 'lunar',\n"," 'missions',\n"," 'lasting',\n"," 'only',\n"," 'a',\n"," 'few',\n"," 'days',\n"," '.',\n"," '</s>',\n"," '<s>',\n"," '<s>',\n"," 'any',\n"," 'lunar',\n"," 'satellite',\n"," 'needs',\n"," 'fuel',\n"," 'to',\n"," 'do',\n"," 'regular',\n"," 'orbit',\n"," 'corrections',\n"," 'and',\n"," 'when',\n"," 'its',\n"," 'fuel',\n"," 'runs',\n"," 'out',\n"," 'it',\n"," 'will',\n"," 'crash',\n"," 'within',\n"," 'months',\n"," '.',\n"," '</s>']"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["word_count = Counter(corpus)\n","sorted(word_count.items(), key=lambda pair: pair[1], reverse=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWtIBbu0gCm0","executionInfo":{"status":"ok","timestamp":1699467649497,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"3f3cb56c-3d4a-4312-cd45-94c92c18aacf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('<s>', 6),\n"," ('fuel', 4),\n"," ('lunar', 3),\n"," ('.', 3),\n"," ('</s>', 3),\n"," ('any', 2),\n"," ('satellite', 2),\n"," ('needs', 2),\n"," ('to', 2),\n"," ('do', 2),\n"," ('regular', 2),\n"," ('orbit', 2),\n"," ('corrections', 2),\n"," ('and', 2),\n"," ('when', 2),\n"," ('its', 2),\n"," ('runs', 2),\n"," ('out', 2),\n"," ('it', 2),\n"," ('will', 2),\n"," ('crash', 2),\n"," ('within', 2),\n"," ('months', 2),\n"," ('the', 2),\n"," ('orbits', 1),\n"," ('of', 1),\n"," ('apollo', 1),\n"," ('motherships', 1),\n"," ('changed', 1),\n"," ('noticeably', 1),\n"," ('during', 1),\n"," ('missions', 1),\n"," ('lasting', 1),\n"," ('only', 1),\n"," ('a', 1),\n"," ('few', 1),\n"," ('days', 1)]"]},"metadata":{},"execution_count":146}]},{"cell_type":"code","source":["M = 10\n","\n","vocabulary = Counter(word_count).most_common(M)\n","\n","# Teniamo nel nostro vocabolario solamente le parole, senza il conteggio di quante volte compaiono\n","vocabulary = [word for word, frequency in vocabulary]\n","# Siccome abbiamo delle parole non presenti nel nostro vocabolario, aggiungiamoci anche il token UNK (e se non presenti già, i token <s> e </s>)\n","vocabulary.append('UNK')\n"],"metadata":{"id":"RKFExTLFf26N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocabulary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLTXwlvSgtIb","executionInfo":{"status":"ok","timestamp":1699467956687,"user_tz":-60,"elapsed":362,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"d7480a38-3926-459c-ad2e-43a2c95bfb39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s>',\n"," 'fuel',\n"," 'lunar',\n"," '.',\n"," '</s>',\n"," 'any',\n"," 'satellite',\n"," 'needs',\n"," 'to',\n"," 'do',\n"," 'UNK']"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","source":["sentence = ['any','lunar','satellite','needs','fuel','to','do','regular','orbit','corrections']\n","output_sentence = []\n","print(f\"input sentence: {sentence}\")\n","\n","for w in sentence:\n","    # test if word w is in vocabulary\n","    if w in vocabulary:\n","        output_sentence.append(w)\n","    else:\n","        output_sentence.append('UNK')\n","\n","print(f\"output sentence: {output_sentence}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqJ792QHf8p4","executionInfo":{"status":"ok","timestamp":1699467956970,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"f6c87cf9-28c7-4a1e-d368-0cbd5480cfcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input sentence: ['any', 'lunar', 'satellite', 'needs', 'fuel', 'to', 'do', 'regular', 'orbit', 'corrections']\n","output sentence: ['any', 'lunar', 'satellite', 'needs', 'fuel', 'to', 'do', 'UNK', 'UNK', 'UNK']\n"]}]},{"cell_type":"markdown","source":["# Definiamo le tecniche per modellare anche la presenza di token non contenuti nel nostro vocabolario"],"metadata":{"id":"AxUfVlsrNIjn"}},{"cell_type":"markdown","source":["## Smoothing"],"metadata":{"id":"y3x5s34phgzP"}},{"cell_type":"code","source":["def add_k_smooting_probability(k, vocabulary_size, n_gram_count, n_gram_prefix_count):\n","    numerator = n_gram_count + k\n","    denominator = n_gram_prefix_count + k * vocabulary_size\n","    return numerator / denominator\n","\n","trigram_probabilities = {('any', 'lunar', 'satellite') : 3}\n","bigram_probabilities = {( 'any', 'lunar') : 10}\n","vocabulary_size = 10\n","k = 3\n","\n","probability_known_trigram = add_k_smooting_probability(k, vocabulary_size, trigram_probabilities[('any', 'lunar', 'satellite')],\n","                           bigram_probabilities[( 'any', 'lunar')])\n","\n","probability_unknown_trigram = add_k_smooting_probability(k, vocabulary_size, 0, 0)\n","\n","print(f\"probability_known_trigram: {probability_known_trigram}\")\n","print(f\"probability_unknown_trigram: {probability_unknown_trigram}\")\n"],"metadata":{"id":"an2xR0BVf8se","executionInfo":{"status":"ok","timestamp":1699467959291,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61e8539f-1742-413e-db4c-089dbcef2d77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["probability_known_trigram: 0.15\n","probability_unknown_trigram: 0.1\n"]}]},{"cell_type":"markdown","source":["## Back-off"],"metadata":{"id":"HxCaz5Izhdrt"}},{"cell_type":"code","source":["# pre-calculated probabilities of all types of n-grams\n","trigram_probabilities = {('any', 'lunar', 'satellite'): 0}\n","bigram_probabilities = {( 'lunar', 'satellite'): 0.3}\n","unigram_probabilities = {'satellite': 0.4}\n","\n","# this is the input trigram we need to estimate\n","trigram = ('large', 'mars', 'satellite')\n","\n","# find the last bigram and unigram of the input\n","bigram = trigram[1: 3]\n","unigram = trigram[2]\n","print(f\"besides the trigram {trigram} we also use bigram {bigram} and unigram ({unigram})\\n\")\n","\n","# 0.4 is used as an example, experimentally found for web-scale corpuses when using the \"stupid\" back-off\n","lambda_factor = 0.4\n","probability_hat_trigram = 0\n","\n","# search for first non-zero probability starting with trigram\n","# to generalize this for any order of n-gram hierarchy,\n","# you could loop through the probability dictionaries instead of if/else cascade\n","if trigram not in trigram_probabilities or trigram_probabilities[trigram] == 0:\n","    print(f\"probability for trigram {trigram} not found\")\n","\n","    if bigram not in bigram_probabilities or bigram_probabilities[bigram] == 0:\n","        print(f\"probability for bigram {bigram} not found\")\n","\n","        if unigram in unigram_probabilities:\n","            print(f\"probability for unigram {unigram} found\\n\")\n","            probability_hat_trigram = lambda_factor * lambda_factor * unigram_probabilities[unigram]\n","        else:\n","            probability_hat_trigram = 0\n","    else:\n","        probability_hat_trigram = lambda_factor * bigram_probabilities[bigram]\n","else:\n","    probability_hat_trigram = trigram_probabilities[trigram]\n","\n","print(f\"probability for trigram {trigram} estimated as {probability_hat_trigram}\")\n"],"metadata":{"id":"fudzPShff8ux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699467959637,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"3c81b394-7d06-49a7-d5c8-c8436add1740"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["besides the trigram ('large', 'mars', 'satellite') we also use bigram ('mars', 'satellite') and unigram (satellite)\n","\n","probability for trigram ('large', 'mars', 'satellite') not found\n","probability for bigram ('mars', 'satellite') not found\n","probability for unigram satellite found\n","\n","probability for trigram ('large', 'mars', 'satellite') estimated as 0.06400000000000002\n"]}]},{"cell_type":"markdown","source":["## Interpolation"],"metadata":{"id":"d9B-_ZqahaCZ"}},{"cell_type":"code","source":["# pre-calculated probabilities of all types of n-grams\n","trigram_probabilities = {('any', 'lunar', 'satellite'): 0}\n","bigram_probabilities = {( 'lunar', 'satellite'): 0.3}\n","unigram_probabilities = {'satellite': 0.4}\n","\n","\n","# the weights come from optimization on a validation set\n","lambda_1 = 0.8\n","lambda_2 = 0.15\n","lambda_3 = 0.05\n","\n","# this is the input trigram we need to estimate\n","trigram = ('large', 'mars', 'satellite')\n","\n","# find the last bigram and unigram of the input\n","bigram = trigram[1: 3]\n","unigram = trigram[2]\n","print(f\"besides the trigram {trigram} we also use bigram {bigram} and unigram ({unigram})\\n\")\n","\n","# in the production code, you would need to check if the probability n-gram dictionary contains the n-gram\n","probability_hat_trigram = lambda_1 * trigram_probabilities.get(trigram, 0)\\\n","+ lambda_2 * bigram_probabilities.get(bigram, 0)\\\n","+ lambda_3 * unigram_probabilities.get(unigram, 0)\n","\n","print(f\"estimated probability of the input trigram {trigram} is {probability_hat_trigram}\")\n"],"metadata":{"id":"eGWmXV9Df8w4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699467959959,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"a6862dd9-e9f2-4cdd-e22f-b31941b8c36e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["besides the trigram ('large', 'mars', 'satellite') we also use bigram ('mars', 'satellite') and unigram (satellite)\n","\n","estimated probability of the input trigram ('large', 'mars', 'satellite') is 0.020000000000000004\n"]}]},{"cell_type":"markdown","source":["# Costruiamo un Language Model in grado di generare probabilità anche per combinazioni di n-gram appartenenti al vocabolario ma mai visti"],"metadata":{"id":"mN43oxWLOLMw"}},{"cell_type":"markdown","source":["## Convertiamo le parole fuori dal vocabolario nel token *UNK*"],"metadata":{"id":"Vp4IF22dA8Lu"}},{"cell_type":"code","source":["train_news_texts_sample_processed_unk = []\n","for sentence in train_news_texts_sample_processed:\n","  new_sentence = []\n","  for word in sentence:\n","    if word not in vocabulary:\n","      new_sentence.append('UNK')\n","    else:\n","      new_sentence.append(word)\n","  train_news_texts_sample_processed_unk.append(new_sentence)"],"metadata":{"id":"y5Ge9kWQAu0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_news_texts_sample_processed_unk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9m1QXZOeNTxr","executionInfo":{"status":"ok","timestamp":1699468364272,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"954760f8-ce05-4f9f-cf49-3501901f9d3d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['<s>',\n","  '<s>',\n","  'any',\n","  'lunar',\n","  'satellite',\n","  'needs',\n","  'fuel',\n","  'to',\n","  'do',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'fuel',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  '.',\n","  '</s>'],\n"," ['<s>',\n","  '<s>',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'lunar',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  '.',\n","  '</s>'],\n"," ['<s>',\n","  '<s>',\n","  'any',\n","  'lunar',\n","  'satellite',\n","  'needs',\n","  'fuel',\n","  'to',\n","  'do',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'fuel',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  'UNK',\n","  '.',\n","  '</s>']]"]},"metadata":{},"execution_count":207}]},{"cell_type":"code","source":["n = 3\n","trigrams_list = [sentence_to_ngram(tokenized_sentence, n) for tokenized_sentence in train_news_texts_sample_processed_unk]\n","trigrams_list = [tuple(x) for y in trigrams_list for x in y]\n","count_trigrams = Counter(trigrams_list)\n","\n","# Siccome dobbiamo applicare il k-smoothing, dobbiamo calcolare anche i conteggi dei bi-grammi, non solo dei tri-grammi\n","bigrams_list = [sentence_to_ngram(tokenized_sentence, n-1) for tokenized_sentence in train_news_texts_sample_processed_unk]\n","bigrams_list = [tuple(x) for y in bigrams_list for x in y]\n","count_bigrams = Counter(bigrams_list)\n"],"metadata":{"id":"ABzCqnyrOKKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def single_pass_ngram_probability_matrix_k_smoothing(k, n,  count_ngrams, count_n_minus_one_grams, vocabulary):\n","    \"\"\"\n","    Crea la matrice di probabilità utilizzando i conteggi degli n-grammi.\n","\n","    Args:\n","        k: fattore di smoothing da applicare\n","        n: numero degli n-grammi\n","        count_ngrams: Conteggio dei n-grammi presenti nel corpus\n","        count_n_minus_one_grams: Conteggio degli n-1-grammi presenti nel corpus\n","        vocabulary: lista di parole/token che fanno parte del nostro vocabolario\n","\n","    Returns:\n","        n_minus_one_grams: lista di tutti i bigrammi, utilizzato come indice di riga della matrice\n","        vocabulary: lista di tutte le parole presenti nel corpus, utilizzato come indice di colonna\n","        count_matrix: pandas dataframe con i bigrammi prefixes come righe,\n","                      le parole del vocabolario come colonne\n","                      e il conteggio delle combinazioni bigramma/parola come valore\n","    \"\"\"\n","    n_minus_one_grams = []\n","    prob_matrix_dict = defaultdict(dict)\n","    vocabulary_no_end_token = vocabulary.copy()\n","    vocabulary_no_end_token.remove('</s>')\n","    vocabulary_combinations = list(itertools.product(vocabulary_no_end_token, repeat=(n-1)))\n","    vocabulary_combinations = [x for x in vocabulary_combinations if not(x[0]!='<s>'\n","     and x[1]=='<s>')]\n","\n","    vocabulary_no_start_token = vocabulary.copy()\n","    vocabulary_no_start_token.remove('<s>')\n","    vocabulary_size = len(vocabulary_no_start_token)\n","\n","    for comb in vocabulary_combinations:\n","      n_gram_prefix_count = count_n_minus_one_grams.get(comb, 0)\n","      for word in vocabulary_no_start_token:\n","        n_gram_count = count_ngrams.get(comb + (word,), 0)\n","        prob_matrix_dict[comb,word] = add_k_smooting_probability(k, vocabulary_size, n_gram_count, n_gram_prefix_count)\n","\n","    # convert the count_matrix to np.array to fill in the blanks\n","    prob_matrix = np.zeros((len(vocabulary_combinations), vocabulary_size))\n","    for ngram_key, ngram_count in prob_matrix_dict.items():\n","      prob_matrix[vocabulary_combinations.index(ngram_key[0]), \\\n","                     vocabulary_no_start_token.index(ngram_key[1])] = ngram_count\n","\n","    # np.array to pandas dataframe conversion\n","    prob_matrix = pd.DataFrame(prob_matrix, index=vocabulary_combinations, columns=vocabulary_no_start_token)\n","    return vocabulary_combinations, prob_matrix\n"],"metadata":{"id":"FLTUQA_UOavo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k=1\n","n_minus_one_grams, prob_matrix = single_pass_ngram_probability_matrix_k_smoothing(k, n,\n","                                                                                  count_trigrams,\n","                                                                                  count_bigrams,\n","                                                                                  vocabulary)"],"metadata":{"id":"4dk7A8HMOku_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prob_matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"WVXB8plJOm_S","executionInfo":{"status":"ok","timestamp":1699468420076,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"342a8ed3-6cc9-44d0-f69b-197f8427adaf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      fuel     lunar         .      </s>       any  satellite  \\\n","(<s>, <s>)        0.076923  0.076923  0.076923  0.076923  0.230769   0.076923   \n","(<s>, fuel)       0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(<s>, lunar)      0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(<s>, .)          0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(<s>, any)        0.083333  0.250000  0.083333  0.083333  0.083333   0.083333   \n","...                    ...       ...       ...       ...       ...        ...   \n","(UNK, satellite)  0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(UNK, needs)      0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(UNK, to)         0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(UNK, do)         0.100000  0.100000  0.100000  0.100000  0.100000   0.100000   \n","(UNK, UNK)        0.066667  0.044444  0.088889  0.022222  0.022222   0.022222   \n","\n","                     needs        to        do       UNK  \n","(<s>, <s>)        0.076923  0.076923  0.076923  0.153846  \n","(<s>, fuel)       0.100000  0.100000  0.100000  0.100000  \n","(<s>, lunar)      0.100000  0.100000  0.100000  0.100000  \n","(<s>, .)          0.100000  0.100000  0.100000  0.100000  \n","(<s>, any)        0.083333  0.083333  0.083333  0.083333  \n","...                    ...       ...       ...       ...  \n","(UNK, satellite)  0.100000  0.100000  0.100000  0.100000  \n","(UNK, needs)      0.100000  0.100000  0.100000  0.100000  \n","(UNK, to)         0.100000  0.100000  0.100000  0.100000  \n","(UNK, do)         0.100000  0.100000  0.100000  0.100000  \n","(UNK, UNK)        0.022222  0.022222  0.022222  0.666667  \n","\n","[91 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-75f383bc-7fa2-4e9e-8109-a7ef13a18295\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fuel</th>\n","      <th>lunar</th>\n","      <th>.</th>\n","      <th>&lt;/s&gt;</th>\n","      <th>any</th>\n","      <th>satellite</th>\n","      <th>needs</th>\n","      <th>to</th>\n","      <th>do</th>\n","      <th>UNK</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(&lt;s&gt;, &lt;s&gt;)</th>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.230769</td>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.076923</td>\n","      <td>0.153846</td>\n","    </tr>\n","    <tr>\n","      <th>(&lt;s&gt;, fuel)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(&lt;s&gt;, lunar)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(&lt;s&gt;, .)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(&lt;s&gt;, any)</th>\n","      <td>0.083333</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>(UNK, satellite)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(UNK, needs)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(UNK, to)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(UNK, do)</th>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>(UNK, UNK)</th>\n","      <td>0.066667</td>\n","      <td>0.044444</td>\n","      <td>0.088889</td>\n","      <td>0.022222</td>\n","      <td>0.022222</td>\n","      <td>0.022222</td>\n","      <td>0.022222</td>\n","      <td>0.022222</td>\n","      <td>0.022222</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>91 rows × 10 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75f383bc-7fa2-4e9e-8109-a7ef13a18295')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-75f383bc-7fa2-4e9e-8109-a7ef13a18295 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-75f383bc-7fa2-4e9e-8109-a7ef13a18295');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7af321e4-4c06-44f6-8c7e-321fe980d5e1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7af321e4-4c06-44f6-8c7e-321fe980d5e1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7af321e4-4c06-44f6-8c7e-321fe980d5e1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":220}]},{"cell_type":"code","source":["prob_matrix.sum(axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAzZN-26HFRX","executionInfo":{"status":"ok","timestamp":1699468432203,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"9818291b-2bef-4c1a-e2ae-bbe97c72d355"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<s>, <s>)          1.0\n","(<s>, fuel)         1.0\n","(<s>, lunar)        1.0\n","(<s>, .)            1.0\n","(<s>, any)          1.0\n","                   ... \n","(UNK, satellite)    1.0\n","(UNK, needs)        1.0\n","(UNK, to)           1.0\n","(UNK, do)           1.0\n","(UNK, UNK)          1.0\n","Length: 91, dtype: float64"]},"metadata":{},"execution_count":222}]},{"cell_type":"markdown","source":["## Generiamo del testo utilizzando il nostro language model, con il nostro vocabolario e la possbilità di generare anche trigrammi non presenti nel nostro corpus di testi"],"metadata":{"id":"_6fkQ8pEBz8e"}},{"cell_type":"code","source":["def generate_text(n: int, prob_matrix: pd.DataFrame, token_count: int, threshold_prob = 0.005, random_sampling: bool = False):\n","    \"\"\"\n","    Funzione per generare del testo partendo dalla matrice di probabilità.\n","\n","    Args:\n","        n: modello n-gramma da utilizzare\n","        prob_matrix: matrice di probabilità\n","        token_count: numero di token da generare\n","        threshold_prob: soglia di probabilità sopra la quale considerare i token\n","        random_sampling: booleano che dice se effettuare un sampling tra i token a probabilità non nulla oppure prendere sempre quello a probabilità massima\n","\n","    Returns:\n","        bigrams: lista di tutti i bigrammi, utilizzato come indice di riga della matrice\n","        vocabulary: lista di tutte le parole presenti nel corpus, utilizzato come indice di colonna\n","        count_matrix: pandas dataframe con i bigrammi prefixes come righe,\n","                      le parole del vocabolario come colonne\n","                      e il conteggio delle combinazioni bigramma/parola come valore\n","    \"\"\"\n","    context_queue = (n - 1) * ['<s>']\n","    result = []\n","    for _ in range(token_count):\n","      if random_sampling:\n","        if tuple(context_queue) in prob_matrix.index.tolist():\n","          nonzero_probs = (prob_matrix.loc[[tuple(context_queue)]]> threshold_prob).any()\n","          tokens_list = nonzero_probs.index[nonzero_probs].tolist()\n","          obj = random.sample(tokens_list, 1)[0]\n","        else:\n","          return ' '.join(result)\n","      else:\n","        obj = prob_matrix.loc[[tuple(context_queue)]].max().idxmax()\n","      result.append(obj)\n","      if n > 1:\n","          context_queue.pop(0)\n","          if obj == '.':\n","              context_queue = (n - 1) * ['<s>']\n","          else:\n","              context_queue.append(obj)\n","    return ' '.join(result)\n"],"metadata":{"id":"9nLRTz92Sv1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  print(generate_text(n, prob_matrix, 20, random_sampling=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE8YmgIyCWI3","executionInfo":{"status":"ok","timestamp":1699468437124,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"3f0fbdac-0225-467d-f9bd-e43dd3a9288b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n","any lunar satellite needs fuel to do UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n"]}]},{"cell_type":"code","source":["for i in range(10):\n","  print(generate_text(n, prob_matrix, 20, random_sampling=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3x36rWuCWc6","executionInfo":{"status":"ok","timestamp":1699468437484,"user_tz":-60,"elapsed":363,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"ccb2420f-54dc-44e8-f868-f023fbb9bf75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["to lunar satellite satellite </s>\n","lunar lunar satellite </s>\n","fuel to lunar satellite </s>\n","do satellite to any needs needs any to fuel do needs fuel needs </s>\n","to UNK satellite to fuel needs . UNK fuel fuel </s>\n","fuel any </s>\n","do UNK fuel do any lunar UNK to satellite UNK lunar lunar do . </s>\n","UNK UNK needs satellite satellite any any to UNK satellite UNK satellite needs needs lunar . fuel satellite to fuel\n","</s>\n","lunar UNK satellite fuel do to UNK UNK fuel UNK </s>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wYEYyC0sFmAl"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdO7EgcDNmrNK4UY5VLtpJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}