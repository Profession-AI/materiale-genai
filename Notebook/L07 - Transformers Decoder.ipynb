{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXmEE/ZkJuZpkFwavqh77p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"24e298c455844996b15274b454778de3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a73a5d6e8b4b414a9422cdb3d534810a","IPY_MODEL_fc198a4f393c43a1ba9ba0f015c84647","IPY_MODEL_1f6a4b1cc8134dd7a32c5f685f4ad417"],"layout":"IPY_MODEL_b6479a4d68884f8f8b6cc27a6eed5882"}},"a73a5d6e8b4b414a9422cdb3d534810a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b06adca3a3c4e03a596f453d309dfa1","placeholder":"​","style":"IPY_MODEL_f98b8dc03b03459799559263470037e1","value":"pytorch_model.bin: 100%"}},"fc198a4f393c43a1ba9ba0f015c84647":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bbb70b9aa8840d1bba4be550c98a5fb","max":989691346,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf012f4e1592494fbc3c3243503efd1e","value":989691346}},"1f6a4b1cc8134dd7a32c5f685f4ad417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ab6d7b5f4ed4c3baaf40fbdd0c2118c","placeholder":"​","style":"IPY_MODEL_1566e8b282f54066b325fe1d45ad156d","value":" 990M/990M [00:38&lt;00:00, 18.3MB/s]"}},"b6479a4d68884f8f8b6cc27a6eed5882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b06adca3a3c4e03a596f453d309dfa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98b8dc03b03459799559263470037e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bbb70b9aa8840d1bba4be550c98a5fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf012f4e1592494fbc3c3243503efd1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ab6d7b5f4ed4c3baaf40fbdd0c2118c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1566e8b282f54066b325fe1d45ad156d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers==4.16.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5xgVUvXso3k","executionInfo":{"status":"ok","timestamp":1700668749566,"user_tz":-60,"elapsed":6520,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"ebd47cec-43a1-4b2d-8e2c-f8373e89b08c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.16.0 in /usr/local/lib/python3.10/dist-packages (4.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (2.31.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.1.1)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (0.15.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.0) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.16.0) (2023.7.22)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.0) (1.3.2)\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoConfig, EncoderDecoderModel\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from math import sqrt"],"metadata":{"id":"QYSk31I9s4I0","executionInfo":{"status":"ok","timestamp":1700933146898,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3QIqxsqPlt59"},"source":["# Transformer Decoder"]},{"cell_type":"markdown","source":["Come abbiamo visto nella sezione di teoria, il blocco Decoder calcola l'attention in maniera similare al blocco Encoder, tuttavia, l'attenzione non viene messa su tutti i token di input, ma solamente su quelli non mascherati, ovvero quelli antecedenti alla parola/token che stiamo considerando"],"metadata":{"id":"vXBngmqLuyub"}},{"cell_type":"markdown","source":["Ricalcoliamo quindi i nostri vettori di query, key e value"],"metadata":{"id":"Ti3ENVd0vHyV"}},{"cell_type":"code","source":["model_ckpt = \"patrickvonplaten/bert2bert_cnn_daily_mail\"\n","text = \"time flies like an arrow\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","model = EncoderDecoderModel.from_pretrained(model_ckpt)"],"metadata":{"id":"p-dIKkJXswjk","executionInfo":{"status":"ok","timestamp":1700933195915,"user_tz":-60,"elapsed":47537,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["24e298c455844996b15274b454778de3","a73a5d6e8b4b414a9422cdb3d534810a","fc198a4f393c43a1ba9ba0f015c84647","1f6a4b1cc8134dd7a32c5f685f4ad417","b6479a4d68884f8f8b6cc27a6eed5882","5b06adca3a3c4e03a596f453d309dfa1","f98b8dc03b03459799559263470037e1","9bbb70b9aa8840d1bba4be550c98a5fb","bf012f4e1592494fbc3c3243503efd1e","9ab6d7b5f4ed4c3baaf40fbdd0c2118c","1566e8b282f54066b325fe1d45ad156d"]},"outputId":"43529f4a-3091-4b43-fefd-e2617d5e26e8"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e298c455844996b15274b454778de3"}},"metadata":{}}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDyGTvaaeOwl","executionInfo":{"status":"ok","timestamp":1700933195916,"user_tz":-60,"elapsed":12,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"84957ddf-0b31-4a9b-e269-3b4c97e908e9"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoderModel(\n","  (encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): BertLMHeadModel(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (cls): BertOnlyMLMHead(\n","      (predictions): BertLMPredictionHead(\n","        (transform): BertPredictionHeadTransform(\n","          (dense): Linear(in_features=768, out_features=768, bias=True)\n","          (transform_act_fn): GELUActivation()\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","inputs.input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Spd-QqdRsy9u","executionInfo":{"status":"ok","timestamp":1700933837980,"user_tz":-60,"elapsed":318,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"ce91ca10-9a16-427d-9462-a050851ba822"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2051, 10029,  2066,  2019,  8612]])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(model_ckpt)\n","token_emb = nn.Embedding(config.vocab_size, config.decoder.hidden_size)\n","token_emb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-R50k7xDvg98","executionInfo":{"status":"ok","timestamp":1700933860325,"user_tz":-60,"elapsed":459,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"f1b1532b-59bb-44c0-b0b7-004df5b46016"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["inputs_embeds = token_emb(inputs.input_ids)\n","inputs_embeds.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLwPG0nBvi_V","executionInfo":{"status":"ok","timestamp":1700933884177,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"4a2a6913-8cff-4286-cf27-5704cfc42d13"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Definiamo una matrice di maschera che rende visibili solamente i token di input antecedenti a quello che stiamo considerando! La maschera assume quindi la forma di una matrice triangolare inferiore"],"metadata":{"id":"Opg8kI8QvMdW"}},{"cell_type":"code","execution_count":25,"metadata":{"outputId":"e3d2867c-1346-4ed7-e6e5-bc42773e77fe","colab":{"base_uri":"https://localhost:8080/"},"id":"LJKoX17Vsjh5","executionInfo":{"status":"ok","timestamp":1700933885132,"user_tz":-60,"elapsed":543,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0.],\n","        [1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1.]])"]},"metadata":{},"execution_count":25}],"source":["seq_len = inputs.input_ids.size(-1)\n","mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)\n","mask[0]"]},{"cell_type":"code","source":["mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DwbVBLkyIFe","executionInfo":{"status":"ok","timestamp":1700933885651,"user_tz":-60,"elapsed":6,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"c337b7a7-e6e8-41bc-f82f-348e8603903b"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1., 0., 0., 0., 0.],\n","         [1., 1., 0., 0., 0.],\n","         [1., 1., 1., 0., 0.],\n","         [1., 1., 1., 1., 0.],\n","         [1., 1., 1., 1., 1.]]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["Calcoliamo gli scores come fatto per il blocco Encoder"],"metadata":{"id":"6z5_IIw-pC7b"}},{"cell_type":"code","execution_count":27,"metadata":{"id":"jJuxbgpKlt5y","outputId":"c888168f-8f76-4269-b69f-3add8ed3a6ec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700933888332,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 5])"]},"metadata":{},"execution_count":27}],"source":["query = key = value = inputs_embeds\n","dim_k = key.size(-1)\n","scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n","scores.size()"]},{"cell_type":"markdown","source":["Mascheriamo gli scores utilizzando la nostra matrice di maschera"],"metadata":{"id":"vv3_jmsqvxHj"}},{"cell_type":"code","execution_count":28,"metadata":{"outputId":"3fb37eff-8b49-4c4a-af5e-942348aabf54","colab":{"base_uri":"https://localhost:8080/"},"id":"Ww7Cb_HCsjh6","executionInfo":{"status":"ok","timestamp":1700933888718,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[29.3284,    -inf,    -inf,    -inf,    -inf],\n","         [ 1.5654, 27.5266,    -inf,    -inf,    -inf],\n","         [ 0.2496, -0.0899, 29.4625,    -inf,    -inf],\n","         [ 0.0464, -0.1138, -0.1201, 27.7881,    -inf],\n","         [-0.6187,  0.5058,  1.3404, -1.0054, 30.3363]]],\n","       grad_fn=<MaskedFillBackward0>)"]},"metadata":{},"execution_count":28}],"source":["scores.masked_fill(mask == 0, -float(\"inf\"))"]},{"cell_type":"markdown","source":["A questo punto, come fatto in precedenza, ci calcoliamo i nostri valori di Attention andando a passare gli scores in un layer di softmax e poi moltiplicando il risultato con la matrice dei values"],"metadata":{"id":"u1d7B3ZVv8Yk"}},{"cell_type":"code","source":["weights = F.softmax(scores, dim=-1)\n","weights.sum(dim=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tt7dMVhnv7-4","executionInfo":{"status":"ok","timestamp":1700933889386,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"ad02ce93-f85c-4811-cb03-7397a6851baa"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["attn_outputs = torch.bmm(weights, value)\n","attn_outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMMj-DdtwKoF","executionInfo":{"status":"ok","timestamp":1700933890139,"user_tz":-60,"elapsed":2,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"9deed07c-a0a3-445f-8cbf-99d09b88d6f1"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["Riepilogando, creiamo una funzione che calcola i valori di Self-Masked Attention partendo dalle 3 matrici di query, key e value:"],"metadata":{"id":"RwyJ30MxwNAU"}},{"cell_type":"code","execution_count":31,"metadata":{"id":"P8ZveIzxsjh6","executionInfo":{"status":"ok","timestamp":1700933892119,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"outputs":[],"source":["def scaled_dot_product_attention(query, key, value, mask=None):\n","    dim_k = query.size(-1)\n","    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n","    weights = F.softmax(scores, dim=-1)\n","    return weights.bmm(value)"]},{"cell_type":"markdown","source":["Anche per le architetture Decoder possiamo quindi definire i moduli di Attention e MultiHead Attention, necessari per costruire un blocco Decoder"],"metadata":{"id":"5n988kawxy1N"}},{"cell_type":"code","source":["class AttentionHead(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super().__init__()\n","        self.q = nn.Linear(embed_dim, head_dim)\n","        self.k = nn.Linear(embed_dim, head_dim)\n","        self.v = nn.Linear(embed_dim, head_dim)\n","\n","    def forward(self, hidden_state, mask=None):\n","        attn_outputs = scaled_dot_product_attention(\n","            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state), mask=mask)\n","        return attn_outputs"],"metadata":{"id":"gMut54tUwVI-","executionInfo":{"status":"ok","timestamp":1700933895092,"user_tz":-60,"elapsed":325,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config, mask=None):\n","        super().__init__()\n","        embed_dim = config.decoder.hidden_size\n","        num_heads = config.decoder.num_attention_heads\n","        head_dim = embed_dim // num_heads\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n","        )\n","        self.output_linear = nn.Linear(embed_dim, embed_dim)\n","\n","    def forward(self, hidden_state, mask=None):\n","        x = torch.cat([h(hidden_state, mask) for h in self.heads], dim=-1)\n","        x = self.output_linear(x)\n","        return x"],"metadata":{"id":"nqmMSg26yQnO","executionInfo":{"status":"ok","timestamp":1700933904477,"user_tz":-60,"elapsed":319,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["multihead_attn = MultiHeadAttention(config, mask=mask)\n","attn_output = multihead_attn(inputs_embeds)\n","attn_output.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nYcTLWByUfb","executionInfo":{"status":"ok","timestamp":1700933907604,"user_tz":-60,"elapsed":428,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"6ff34b70-f7f9-40c2-f635-5e37396d1be5"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["Definiamo il modulo FeedForward"],"metadata":{"id":"AuzPS3UC1b-E"}},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(config.decoder.hidden_size, config.decoder.intermediate_size)\n","        self.linear_2 = nn.Linear(config.decoder.intermediate_size, config.decoder.hidden_size)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.decoder.hidden_dropout_prob)\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.gelu(x)\n","        x = self.linear_2(x)\n","        x = self.dropout(x)\n","        return x"],"metadata":{"id":"7zaO7BIyyqPs","executionInfo":{"status":"ok","timestamp":1700933929298,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["A questo punto possiamo definire il layer di TransformerDecoder"],"metadata":{"id":"alf5GCRz1hrv"}},{"cell_type":"code","source":["class TransformerDecoderLayer(nn.Module):\n","    def __init__(self, config, mask=None):\n","        super().__init__()\n","        self.layer_norm_1 = nn.LayerNorm(config.decoder.hidden_size)\n","        self.layer_norm_2 = nn.LayerNorm(config.decoder.hidden_size)\n","        self.attention = MultiHeadAttention(config)\n","        self.feed_forward = FeedForward(config)\n","\n","    def forward(self, x, mask=None):\n","        # Apply layer normalization and then copy input into query, key, value\n","        hidden_state = self.layer_norm_1(x)\n","        # Apply attention with a skip connection\n","        x = x + self.attention(hidden_state, mask)\n","        # Apply feed-forward layer with a skip connection\n","        x = x + self.feed_forward(self.layer_norm_2(x))\n","        return x"],"metadata":{"id":"GHih8bmo1hI3","executionInfo":{"status":"ok","timestamp":1700933939450,"user_tz":-60,"elapsed":336,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["class Embeddings(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.token_embeddings = nn.Embedding(config.vocab_size,\n","                                             config.decoder.hidden_size)\n","        self.position_embeddings = nn.Embedding(config.decoder.max_position_embeddings,\n","                                                config.decoder.hidden_size)\n","        self.layer_norm = nn.LayerNorm(config.decoder.hidden_size, eps=1e-12)\n","        self.dropout = nn.Dropout()\n","\n","    def forward(self, input_ids):\n","        # Create position IDs for input sequence\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n","        # Create token and position embeddings\n","        token_embeddings = self.token_embeddings(input_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","        # Combine token and position embeddings\n","        embeddings = token_embeddings + position_embeddings\n","        embeddings = self.layer_norm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings"],"metadata":{"id":"CbOV3Yds2gQM","executionInfo":{"status":"ok","timestamp":1700933979609,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(nn.Module):\n","    def __init__(self, config, mask=None):\n","        super().__init__()\n","        self.embeddings = Embeddings(config)\n","        self.layers = nn.ModuleList([TransformerDecoderLayer(config) for _ in range(config.decoder.num_hidden_layers)])\n","\n","    def forward(self, x, mask):\n","        x = self.embeddings(x)\n","        x = self.layers[0](x, mask)\n","        for layer in self.layers[1:]:\n","            x = layer(x)\n","        return x"],"metadata":{"id":"ZWtoSBhh1rhk","executionInfo":{"status":"ok","timestamp":1700933992185,"user_tz":-60,"elapsed":3,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["decoder = TransformerDecoder(config)\n","decoder(inputs.input_ids, mask).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Cb1ihUf2guL","executionInfo":{"status":"ok","timestamp":1700933997112,"user_tz":-60,"elapsed":3434,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"3b4c0832-61b1-405c-ab6d-cbaeae7dbb41"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 768])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["decoder(inputs.input_ids, mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWQVzZ552nlV","executionInfo":{"status":"ok","timestamp":1700933997554,"user_tz":-60,"elapsed":444,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"8e690bd9-ba0b-4f0d-868f-d7883e968222"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.8775, -2.0814,  2.0657,  ...,  0.1789,  0.3469,  1.0051],\n","         [-1.9024, -2.3523,  0.6836,  ..., -1.6603, -0.7521, -0.4312],\n","         [-1.2800, -0.5740, -4.6542,  ...,  1.2421, -0.7086,  1.7556],\n","         [-3.1928, -3.1439,  3.4209,  ..., -0.0666, -2.0549,  1.4300],\n","         [-1.0770, -1.9408, -2.0219,  ..., -0.3106, -7.5593,  1.3381]]],\n","       grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["decoder"],"metadata":{"id":"Sgxgw9Wy54EP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700934004597,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Negri","userId":"08467063413129502685"}},"outputId":"46b847fa-52b9-4286-c822-954c6402560a"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerDecoder(\n","  (embeddings): Embeddings(\n","    (token_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (layers): ModuleList(\n","    (0-11): 12 x TransformerDecoderLayer(\n","      (layer_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-11): 12 x AttentionHead(\n","            (q): Linear(in_features=768, out_features=64, bias=True)\n","            (k): Linear(in_features=768, out_features=64, bias=True)\n","            (v): Linear(in_features=768, out_features=64, bias=True)\n","          )\n","        )\n","        (output_linear): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (feed_forward): FeedForward(\n","        (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n","        (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n","        (gelu): GELU(approximate='none')\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":[],"metadata":{"id":"X1usF67GkSvy"},"execution_count":null,"outputs":[]}]}